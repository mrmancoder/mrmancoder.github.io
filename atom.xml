<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>愤怒的土豆泥</title>
  
  <subtitle>Blog</subtitle>
  <link href="https://mrmancoder.top/atom.xml" rel="self"/>
  
  <link href="https://mrmancoder.top/"/>
  <updated>2025-05-30T18:26:06.992Z</updated>
  <id>https://mrmancoder.top/</id>
  
  <author>
    <name>Mr.Man</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>test_mac</title>
    <link href="https://mrmancoder.top/posts/6e6e37a2.html"/>
    <id>https://mrmancoder.top/posts/6e6e37a2.html</id>
    <published>2025-05-31T01:28:24.000Z</published>
    <updated>2025-05-30T18:26:06.992Z</updated>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"/><p>直接clone博客源码，安装node_module，之后就可以正常使用了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;/&gt;



&lt;p&gt;直接clone博客源码，安装node_module，之后就可以正常使用了。&lt;/p&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>MySQL主从同步报错排查：Coordinator stopped because there were error(s) in the worker(s).</title>
    <link href="https://mrmancoder.top/posts/99cfcdc2.html"/>
    <id>https://mrmancoder.top/posts/99cfcdc2.html</id>
    <published>2025-05-24T17:49:00.000Z</published>
    <updated>2025-05-30T18:26:06.992Z</updated>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"/><h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h2><p>​    在配置MySQL主从复制后，执行<code>show slave status;</code>查询同步状态，出现报错，Slave_SQL_Running为No，Last_Error是报错信息。</p><p><img src="https://blog.mrmanwen.cn/blog/MySQL%E5%90%8C%E6%AD%A5%E7%8A%B6%E6%80%81%E6%8A%A5%E9%94%99.png" alt=""></p><blockquote><p>Last_Error：Coordinator stopped because there were error(s) in the worker(s). The most recent failure being: Worker 1 failed executing transaction ‘ANONYMOUS’ at source log binlog.000001, end_log_pos 1000. See error log and/or performance_schema.replication_applier_status_by_worker table for more details about this failure or others, if any.</p></blockquote><p>​    顺着报错信息，来到<code>performance_schema.replication_applier_status_by_worker</code>表查看具体信息。</p><blockquote><p>LAST_ERROR_MESSAGE:Worker 1 failed executing transaction ‘ANONYMOUS’ at source log binlog.000001, end_log_pos 1000; Error executing row event: ‘Unknown database ‘nacos’’</p></blockquote><h2 id="2-问题分析"><a href="#2-问题分析" class="headerlink" title="2. 问题分析"></a>2. 问题分析</h2><p>​    分析报错信息，一个工作进程在执行一个匿名事务时发生了报错，具体的问题为:<code>&#39;Unknown database &#39;nacos&#39;&#39;</code>。</p><p>​    主库上对 nacos 数据库进行了某些操作（比如插入、更新、删除数据），这些操作被记录到了binlog中。当从库尝试重放这些操作时，发现在从库环境中并不存在一个叫做 nacos 的数据库，因此抛出错误。</p><h2 id="3-解决办法"><a href="#3-解决办法" class="headerlink" title="3. 解决办法"></a>3. 解决办法</h2><p>​    既然从库没有nacos数据库，那就<strong>手动将主库的nacos库整体复制到从库</strong>，之后再重新开启主从库的同步即可，查询同步状态，问题修复。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;/&gt;

&lt;h2 id=&quot;1-前言&quot;&gt;&lt;a href=&quot;#1-前言&quot; class=&quot;headerlink&quot; title=&quot;1. 前言&quot;&gt;&lt;/a&gt;1. 前言&lt;/h2&gt;&lt;p&gt;​    在配置MySQL</summary>
      
    
    
    
    <category term="MySQL" scheme="https://mrmancoder.top/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://mrmancoder.top/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>常见JVM的异常场景及解决方法</title>
    <link href="https://mrmancoder.top/posts/318ab98f.html"/>
    <id>https://mrmancoder.top/posts/318ab98f.html</id>
    <published>2025-05-19T23:13:27.000Z</published>
    <updated>2025-05-30T18:26:06.992Z</updated>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"/><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>​    对于Java开发人员，不需要直接操作内存，很容易因为编码不规范的情况造成内存使用不当，出现OOM异常，本篇文章来梳理有哪些场景会造成OOM，以及对应的解决方法。</p><div class="note warning flat"><p>注：本篇文章为个人学习所用，可能存在不严谨或出错的地方，还请谅解。</p></div><h2 id="2-Java堆溢出"><a href="#2-Java堆溢出" class="headerlink" title="2. Java堆溢出"></a>2. Java堆溢出</h2><p>​    堆的唯一作用就是存储对象的实例，堆占用的内存是有限的，如果对象实例的大小达到了最大限制，就会出现内存溢出的情况。</p><p>​    下面这段代码是造成堆溢出的代码示例，运行前指定堆大小（如果堆的最小值和最大值相同，堆的大小就不会动态扩展），并配置堆溢出时导出堆转储文件。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.mrman.OOM;</span><br><span class="line"></span><br><span class="line"><span class="comment">//VM options: -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError</span></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HeapOOM</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">TestObject</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        List&lt;TestObject&gt; list = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            list.add(<span class="keyword">new</span> <span class="title class_">TestObject</span>());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>​    得到的结果为：<code>java.lang.OutOfMemoryError: Java heap space</code></p><p><img src="https://blog.mrmanwen.cn/blog/Java%E5%A0%86%E6%BA%A2%E5%87%BA%E7%9A%84output.png" style="zoom:80%;" /></p><p>​    排查的大致思路：利用分析工具（如MAT）分析dump文件，<strong>先确定是内存泄露还是内存溢出</strong>。</p><div class="note warning flat"><p>注：</p><p>​    内存泄露：分配的内存没有办法回收，导致无内存可用；</p><p>​    内存溢出：程序在申请内存时，JVM没有足够的内存分配，不能满足请求。</p></div><ul><li>如果是内存泄露，就要检查泄露对象到GC Roots的引用链，分析泄露对象是如何被引用的，为什么没有被垃圾收集器回收掉。一般通过分析到GC Roots的引用链，就可以得出泄露对象是在哪里被创建的，从而定位出原因。</li><li><p>如果内存溢出，就需要检查堆的配置参数，结合机器的内存，判断是否可以调大堆的最大空间。</p><p>   将上面代码得到的dump文件让MAT分析下，查看Leak Suspects（帮助分析占用内存较多的对象），发现main主线程创建了一个Object[]实例，占用了95.33%的内存。</p></li></ul><p><img src="https://blog.mrmanwen.cn/blog/%E5%A0%86%E6%BA%A2%E5%87%BA_MAT_LeakSuspects.png" style="zoom:80%;" /></p><p>​    MAT中还有一个很常用的指标Dominator tree，Dominator tree是根据对象的引用和支配关系生成的树状支配图，按照Retained Heap大小排序，能清晰的查看对象之间的引用关系。</p><div class="note warning flat"><p>需要介绍两个概念：</p><p>​    Shallow Heap：对象自身占用的内存大小，不包含其属性对象占用的内存大小；</p><p>​    Retained Heap(重点)：指一个对象被GC后，能释放掉的内存大小（是分析内存溢出的一个非常重要的指标）。</p></div><p>​    现在看下Dominator tree，发现Object[]对象实例的Retained Heap为16206520KB，内部共有810325个TestObject示例，占用95.33%的内存。也可以发现每个TestObject关联的是Thread，属于GC Root，所以TestObject对象都无法被回收，从而导致堆溢出。</p><p><img src="https://blog.mrmanwen.cn/blog/JVM%E5%A0%86%E6%BA%A2%E5%87%BA_MAT_DominatorTree.png" style="zoom:80%;" /></p><p><img src="https://blog.mrmanwen.cn/blog/JVM%E5%A0%86%E6%BA%A2%E5%87%BA_MAT_pathToGCRoot.png" style="zoom:80%;" /></p><h2 id="3-虚拟机栈和本地方法栈溢出"><a href="#3-虚拟机栈和本地方法栈溢出" class="headerlink" title="3. 虚拟机栈和本地方法栈溢出"></a>3. 虚拟机栈和本地方法栈溢出</h2><p>​    在《Java虚拟机规范》中对于虚拟机栈和本地方法栈，讲了两种OOM异常：</p><ol><li>如果线程请求的栈深度大于虚拟机栈允许的最大深度，将抛出<code>StackOverflowError</code>异常。</li><li>如果虚拟机的栈允许动态扩展，那么在扩展时无法申请到足够的内存，将抛出<code>OutOfMemoryError</code>异常。</li></ol><p>​    在HotSpot虚拟机中，规定虚拟机栈不可以动态扩展，所以只有创建线程时无法获得足够内存的情况，才会造成OutOfMemoryError异常，其他情况均为StackOverflowError异常，造成StackOverflowError异常的情况也主要有两种：</p><ol><li><p>虚拟机栈整体的内存容量就偏小，无法容纳太多的栈帧；</p></li><li><p>虚拟机栈的内存容量正常，但是栈帧的容量太大（如：方法中定义了很多的本地变量）。</p></li></ol><h2 id="4-多线程下的OutOfMemoryError异常"><a href="#4-多线程下的OutOfMemoryError异常" class="headerlink" title="4. 多线程下的OutOfMemoryError异常"></a>4. 多线程下的OutOfMemoryError异常</h2><p>​    如果将考虑范围扩大到多线程，通过不断地的创建线程，也会造成内存溢出异常。</p><p>​    原因很好理解，系统给每个进程分配的内存是有限的，如果其他区域占用的内存过大，那留给栈的内存就会变小此时有两种情况：</p><ol><li><p>如果此时创建过多的线程，就会迅速将留给栈的内存占满；</p></li><li><p>如果给创建的线程分配栈内存过大，总量不变，能创建的线程数就变小，很快也会被占满。</p></li></ol><p>​    在这种情况下，如果不能减少线程创建的数量，就只能通过减小堆大小或减少栈容量来换取创建更多的线程，这种手段不容易想到。</p><p>​    这里讲一下在实际开发中遇到的例子，程序运行时报错：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">java.lang.OutOfMemoryError:unable to create <span class="keyword">new</span> <span class="title class_">native</span> thread</span><br></pre></td></tr></table></figure><p>​    这个错误说明无法再创建新的线程了，这个时候需要判断是线程数量太多了，还是每个线程分配栈的内存太大了。首先，查询进程的PID信息，确定PID后，查看该进程一共创建了多少线程，以及操作系统规定可以创建的最多线程数：</p><p><img src="https://blog.mrmanwen.cn/blog/%E6%9F%A5%E8%BF%9B%E7%A8%8B%E5%88%9B%E5%BB%BA%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%95%B0.png" alt=""></p><p>​                                <img src="https://blog.mrmanwen.cn/blog/%E6%9C%80%E5%A4%9A%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E6%95%B0.png" alt="">    </p><p>​   发现一共创建了30803个线程，而最大线程数为30823，非常接近，大概可以判断是线程创建的太多了，有了这个猜想后，就可以回到代码，检查线程创建的地方，确实发现了不对劲，创建线程的语句放在了循环里面，导致线程一直被创建。</p><p><img src="https://blog.mrmanwen.cn/blog/%E7%BA%BF%E7%A8%8B%E5%88%9B%E5%BB%BA%E8%BF%87%E5%A4%9A-%E4%BB%A3%E7%A0%81%E6%8E%92%E6%9F%A5.png" style="zoom:80%;" /></p><h2 id="5-方法区和运行时常量池溢出"><a href="#5-方法区和运行时常量池溢出" class="headerlink" title="5. 方法区和运行时常量池溢出"></a>5. 方法区和运行时常量池溢出</h2><p>​   从JDK8开始，元空间永久替换了永久代，元空间直接受限于本地内存的大小，因此元空间出现内存溢出的情况已经很少见了，现在的项目都是JDK8起步了，所以可以不考虑这部分的溢出问题。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;/&gt;

&lt;h2 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1. 引言&quot;&gt;&lt;/a&gt;1. 引言&lt;/h2&gt;&lt;p&gt;​    对于Java开发</summary>
      
    
    
    
    <category term="JVM" scheme="https://mrmancoder.top/categories/JVM/"/>
    
    
    <category term="JVM" scheme="https://mrmancoder.top/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>Java的内存区域划分</title>
    <link href="https://mrmancoder.top/posts/a375f573.html"/>
    <id>https://mrmancoder.top/posts/a375f573.html</id>
    <published>2025-05-18T01:19:18.000Z</published>
    <updated>2025-05-30T18:26:06.992Z</updated>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"/><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>Java和C++的一个关键区别就是对内存的控制，C++需要在编码时直接管理内存，需要开发者对内存的知识了如指掌。而Java却将管理内存的权利交给了Java虚拟机（JVM），使得开发人员不需要执行分配/释放内存等操作，提升了开发效率。但是一旦出现问题，很容易让人摸不清头脑，因此，只有掌握了JVM如何管理内存，处理问题才能如鱼得水，这篇文章从最基本的讲起，讲一讲JVM都包含哪些区域。</p><div class="note warning flat"><p>注：本篇文章为个人学习所用，可能存在不严谨或出错的地方，还请谅解。</p></div><h2 id="2-运行时区域划分"><a href="#2-运行时区域划分" class="headerlink" title="2. 运行时区域划分"></a>2. 运行时区域划分</h2><h3 id="2-1-整体架构图"><a href="#2-1-整体架构图" class="headerlink" title="2.1 整体架构图"></a>2.1 整体架构图</h3><p>本文以JDK1.8版本为例，展开讲解。</p><p><img src="https://blog.mrmanwen.cn/blog/JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9F%EF%BC%881.8%EF%BC%89.png" style="zoom:80%;" /></p><h3 id="2-2-程序计数器"><a href="#2-2-程序计数器" class="headerlink" title="2.2 程序计数器"></a>2.2 程序计数器</h3><p>程序计数器所占用的内存空间很小，可以将他看做线程执行字节码的行号指示器，表示当前执行的具体位置，程序执行过程中，通过修改程序计数器的值来指定下一条需要执行的字节码指令，因此程序的顺序执行、循环、跳转、异常执行等功能都是依赖程序计数器完成的。</p><p>同时，程序在多线程的情况下，需要在多个线程之间轮流切换，为了实现线程切换回来后还能从原来的位置继续执行，每个线程都会有一个独立的程序计数器，不同线程之间互不影响，因此程序计数器是“线程私有”的。</p><h3 id="2-3-Java虚拟机栈"><a href="#2-3-Java虚拟机栈" class="headerlink" title="2.3 Java虚拟机栈"></a>2.3 Java虚拟机栈</h3><p><img src="https://blog.mrmanwen.cn/blog/Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88.png" style="zoom:80%;" /></p><p>Java虚拟机栈表示<strong>Java方法的执行过程</strong>，一个方法被执行，会创建一个对应的栈帧被压入栈中，<strong>栈帧存储方法执行过程中的信息</strong>，包括局部变量表、操作数栈、动态链接、方法返回地址。当方法执行完成后，对应的栈帧就会被执行出栈操作，<strong>一个方法从调用到执行完毕，必然伴随着一个栈帧入栈到出栈的过程。</strong></p><p>Java虚拟机栈和结构和数据结构中的栈相似，先进后出的思想，只有入栈和出栈两种操作。</p><h3 id="2-4-本地方法栈"><a href="#2-4-本地方法栈" class="headerlink" title="2.4 本地方法栈"></a>2.4 本地方法栈</h3><p>本地方法栈和Java虚拟机栈类似，区别只是<strong>虚拟机栈为Java方法服务，本地方法栈是为本地方法服务</strong>。</p><h3 id="2-5-堆"><a href="#2-5-堆" class="headerlink" title="2.5 堆"></a>2.5 堆</h3><p>堆是虚拟机管理区域中占用内存最大的一块，堆的核心概念为：<strong>Java中“几乎”所有对象都是存在堆中的，由堆来给对象实例分配内存。</strong>需要注意的是，这里强调的是“几乎”，因为随着即时编译技术的发展，栈上分配等手段导致出现了新的情况。</p><p>堆的唯一作用就是存放对象实例，也就导致堆成为了垃圾回收（GC）的内存区域，因此堆也被称为“GC堆”。</p><p>在一些资料中，会将堆做细致的区域划分，出现了“新生代”，“老年代”等概念，其实这种区域划分并不是虚拟机实现的具体布局，而是从垃圾分代回收的角度考虑，这种划分是一部分垃圾收集器的共同特性或设计风格。<strong>无论如何，堆的唯一作用就是存放对象实例，将堆做区域划分，唯一的目的是为了更好的回收内存，或更快的分配内存。</strong></p><h3 id="2-6-方法区"><a href="#2-6-方法区" class="headerlink" title="2.6 方法区"></a>2.6 方法区</h3><p>方法区也是线程共享的，但<strong>方法区只是《Java虚拟机规范》规定的一个概念</strong>，至于如何实现方法区，不同虚拟机有自己的方式。</p><p><strong>方法区的作用是存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。</strong>JDK8之前，HotSpot虚拟机使用永久代来实现方法区，在永久代同样采用收集器的分代设计，这样就可以像管理堆一样管理方法区。但是这种方式会导致更容易造成内存溢出的问题，因为永久代是存在上限的，由<code>-XX:MaxPermSize</code>参数控制。到了JDK8，完全废弃了永久代这个概念，改为了元空间实现方法区。</p><p>元空间直接占用本地内存，不再受JVM参数的限制，一方面降低了内存溢出的风险，另一方面，元空间的大小由系统的实际空间控制，这样可以加载的类就更多了。</p><h3 id="2-7-运行时常量池"><a href="#2-7-运行时常量池" class="headerlink" title="2.7 运行时常量池"></a>2.7 运行时常量池</h3><p>运行时常量池是方法区的一部分，Class文件中除了类的版本、字段、方法等描述信息外，还有一项信息是常量池表，用来存储编译器间产生的各种字面量和符号引用，这部分信息会在类加载完成后，存储到运行时常量池中。</p><h3 id="2-8-直接内存"><a href="#2-8-直接内存" class="headerlink" title="2.8 直接内存"></a>2.8 直接内存</h3><p>JDK1.4 中新加入的 NIO（Non-Blocking I/O，也被称为 New I/O），引入了一种基于通道（Channel）与缓存区（Buffer）的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过<strong>一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作</strong>。这样就能在一些场景中显著提高性能，因为<strong>避免了在 Java 堆和 Native 堆之间来回复制数据</strong>。</p><p>直接内存并不是虚拟机运行时数据区的一部分，它分配在本地内存上。他的<strong>核心作用是由Java堆中的对象直接操作堆外内存，不需要将其复制到Java堆中，提高了性能</strong>。直接内存不回收Java堆大小的限制，会收到本地内存的影响，也有可能出现OOM的情况。</p><h2 id="3-参考"><a href="#3-参考" class="headerlink" title="3. 参考"></a>3. 参考</h2><ul><li>《深入理解 Java 虚拟机：JVM 高级特性与最佳实践（第三版）》</li><li><a href="https://javaguide.cn/java/jvm/memory-area.html">https://javaguide.cn/java/jvm/memory-area.html</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;/&gt;

&lt;h2 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1. 概述&quot;&gt;&lt;/a&gt;1. 概述&lt;/h2&gt;&lt;p&gt;Java和C++的一个关键</summary>
      
    
    
    
    <category term="JVM" scheme="https://mrmancoder.top/categories/JVM/"/>
    
    
    <category term="JVM" scheme="https://mrmancoder.top/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>聊聊Kafka到底是什么？</title>
    <link href="https://mrmancoder.top/posts/105f9113.html"/>
    <id>https://mrmancoder.top/posts/105f9113.html</id>
    <published>2024-12-29T18:49:56.000Z</published>
    <updated>2025-05-30T18:26:06.992Z</updated>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"/><h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><p>Kafka <strong>既是一个高性能的分布式流处理平台，也是一个具有高吞吐量、低延迟和高可靠性的消息传递系统</strong>。它不仅仅是一个简单的消息队列，还是一个面向实时数据流处理的基础设施。广泛应用于大数据分析、日志聚合、监控和事件流处理等场景。</p><h2 id="二、Kafka架构分析"><a href="#二、Kafka架构分析" class="headerlink" title="二、Kafka架构分析"></a>二、Kafka架构分析</h2><h3 id="（一）Kafka结构及重要组件"><a href="#（一）Kafka结构及重要组件" class="headerlink" title="（一）Kafka结构及重要组件"></a>（一）Kafka结构及重要组件</h3><p><img src="https://blog.mrmanwen.cn/blog/Kafka%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt=""></p><p>如上图所示，Kafka由Producer、Broker、Consumer 以及负责集群管理的 ZooKeeper 组成，各部分功能如下：</p><ul><li><p><strong>Producer：</strong>生产者，负责消息的创建并通过一定的路由策略发送消息到合适的 Broker； </p></li><li><p><strong>Broker：</strong>服务实例，负责消息的持久化、中转等功能；</p></li><li><strong>Consumer：</strong>消费者，负责从 Broker 中拉取（Pull）订阅的消息并进行消费，通常多个消费者构成一个分组，消息只能被同组中的一个消费者消费；</li><li><p><strong>ZooKeeper：</strong>负责 broker、consumer 集群元数据的管理等，在2.8版本及之后，Kafka移除了对Zookeeper的依赖；</p></li><li><p><strong>topic：</strong>消息主题。Kafka 按 topic 对消息进行分类，我们在收发消息时只需指定 topic。</p></li><li><strong>partition：</strong>分区。为了提升系统的吞吐，一个 topic 下通常有多个 partition，partition 分布在不同的 Broker 上，用于存储 topic 的消息，这使 Kafka 可以在多台机器上处理、存储消息，给 kafka 提供给了并行的消息处理能力和横向扩容能力。另外，为了提升系统的可靠性，partition 通常会分组，且每组有一个主 partition、多个副本 partition，且分布在不同的 broker 上，从而起到容灾的作用。</li><li><strong>segment：</strong>分段。宏观上看，一个 partition 对应一个日志（Log）。由于生产者生产的消息会不断追加到 log 文件末尾，为防止 log 文件过大导致数据检索效率低下，Kafka 采取了分段和索引机制，将每个 partition 分为多个 segment，同时也便于消息的维护和清理。每个 segment 包含一个 .log 日志文件、两个索引(.index、timeindex)文件以及其他可能的文件。每个 Segment 的数据文件以该段中最小的 offset 为文件名，当查找 offset 的 Message 的时候，通过二分查找快找到 Message 所处于的 Segment 中。</li><li><strong>offset：</strong>消息在日志中的位置，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量。offset 是消息在分区中的唯一标识，是一个单调递增且不变的值。Kafka 通过它来保证消息在分区内的顺序性，不过 offset 并不跨越分区，也就是说，Kafka 保证的是分区有序而不是主题有序。</li></ul><h3 id="（二）分区策略"><a href="#（二）分区策略" class="headerlink" title="（二）分区策略"></a>（二）分区策略</h3><p>每个主题内会存在多个分区，为了明确生产者将消息发送给哪个分区，Kafka指定了几种分区策略，其中默认的分区策略为轮询策略。</p><h4 id="1-轮询策略"><a href="#1-轮询策略" class="headerlink" title="1. 轮询策略"></a>1. 轮询策略</h4><p>轮询策略也被称为Round-robin策略，即顺序分配，假如一个topic包括三个分区，分别为0,1,2，生产者共有10个消息，编号为1-10，按顺序分配后，得到的结果如图所示，轮询策略能保证消息最大程度的分配到不同的分区上，也是最合理的分区策略。</p><p><img src="https://blog.mrmanwen.cn/blog/kafka_%E8%BD%AE%E8%AF%A2%E7%AD%96%E7%95%A5.png" alt=""></p><h4 id="2-随机策略"><a href="#2-随机策略" class="headerlink" title="2. 随机策略"></a>2. 随机策略</h4><p>随机策略也称为Randomness策略。所谓随机就是我们随意地将消息放置到任意一个分区上，在代码中先获取分区的个数N，然后随机获取一个小于N的正整数。随机策略本质上是将消息平均分配到分区上，但是会出现分区之间分配消息不均匀的情况，这也正是Kafka官方在新版本中将默认分区策略从随机策略改为轮询策略。</p><h4 id="3-消费Key值顺序策略"><a href="#3-消费Key值顺序策略" class="headerlink" title="3. 消费Key值顺序策略"></a>3. 消费Key值顺序策略</h4><p>Kafka 允许为每条消息定义消息键，简称为 Key。这个 Key是一个有着明确业务含义的字符串，比如工号、部门编号或是业务 ID 等；一旦消息被定义了 Key，那么就可以保证同一个Key 的所有消息都进入到相同的分区里面，这样做的优势在于可以根据业务场景对消息进行分组，在消息消费时能够极大的提高消息处理的吞吐量。由于每个分区下的消息处理都是有顺序的，所以这个策略被称为消息Key值顺序策略。如果指定了 Key，那么默认实现按消息键保序策略；如果没有指定 Key，则使用轮询策略。如下图所示。</p><p><img src="https://blog.mrmanwen.cn/blog/kafka%E6%B6%88%E8%B4%B9Key%E5%80%BC%E9%A1%BA%E5%BA%8F%E7%AD%96%E7%95%A5.png" alt=""></p><h4 id="4-自定义策略"><a href="#4-自定义策略" class="headerlink" title="4. 自定义策略"></a>4. 自定义策略</h4><p>Kafka提供了可自定义策略，因此开发人员可以自己定义具体策略。可以编写一个实现类实现 org.apache.kafka.clients.producer.Partitioner接口中的partition方法，然后在生产者端配置partition.class为实现类的全类名即可。观察Kafka源码发现，Kafka的默认分区器DefaultPartitioner类也实现了此方法，此方法的参数包括主题、分区、集群等，如图所示，可见Kafka提供足够多的信息让开发人员实现自定义策略。</p><p><img src="https://blog.mrmanwen.cn/blog/Kafka-%E8%87%AA%E5%AE%9A%E4%B9%89%E7%AD%96%E7%95%A5.png" alt=""></p><h3 id="（三）消费者的位移提交机制"><a href="#（三）消费者的位移提交机制" class="headerlink" title="（三）消费者的位移提交机制"></a>（三）消费者的位移提交机制</h3><p>生产者将消息按照策略发送到分区之后，消息的下一个处理阶段是由消费者消费。Consumer利用偏移量offset记录了Consumer要消费的下一条消息的位移。在消息被消费后，Consumer会向Kafka提交自己的位移信息，即告诉Kafka我消费到什么位置了，这样当 Consumer 发生故障重启之后，就能够从 Kafka 中读取之前提交的位移值，然后从相应的位移处继续消费，从而避免整个消费过程重来一遍，此过程被叫做位移提交。由于消息只在分区中保证其有序性，因此Consumer会为分配给他的每个分区都维护一个offset。Kafka提供了两种提交机制，分别为自动提交和手动提交。</p><h4 id="1-自动提交"><a href="#1-自动提交" class="headerlink" title="1. 自动提交"></a>1. 自动提交</h4><p>自动提交是指Consumer在后台默默地提交位移，要想开启Consumer的自动提交，只需要将参数 enable.auto.commit设置为true即可，同时还需要关注一个参数：auto.commit.interval.ms。它表示多久自动提交一次，默认值是 5 秒。</p><h4 id="2-手动提交"><a href="#2-手动提交" class="headerlink" title="2. 手动提交"></a>2. 手动提交</h4><p>手动提交是指消费完消息后，在代码中手动向Kafka做位移提交。开启手动提交的方法是将enable.auto.commit置为false，然后在代码中调用<strong>commitSync()</strong>方法提交最新的位移，此方式为同步提交，同步提交的优势在于更加灵活，能够手动把控提交位移的时机。但是，同步提交也有缺陷，就是在调用 commitSync() 时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果，这个状态才会结束，会造成系统短暂的阻塞，在代码中的实现如下：</p><p><img src="https://blog.mrmanwen.cn/blog/kafka-%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4%E4%BB%A3%E7%A0%81.png" alt=""></p><p>为了避免同步提交造成阻塞的问题，Kafka还支持异步提交，即<strong>commitAsync()</strong>方法，该方法是一个异步操作。调用 commitAsync() 之后，它会立即返回，不会阻塞。同时Kafka还提供了回调函数（callback），用来实现提交之后的逻辑，比如记录日志或处理异常等。异步提交在代码中的实现如下：</p><p><img src="https://blog.mrmanwen.cn/blog/kafka-%E5%BC%82%E6%AD%A5%E6%8F%90%E4%BA%A4.png" alt=""></p><h3 id="（四）Kafka为什么这么快-“零拷贝”"><a href="#（四）Kafka为什么这么快-“零拷贝”" class="headerlink" title="（四）Kafka为什么这么快-“零拷贝”"></a>（四）Kafka为什么这么快-“零拷贝”</h3><p>Kafka 中存在大量的网络数据持久化到磁盘（Producer 到 Broker）和磁盘文件通过网络发送（Broker 到 Consumer）的过程，这一过程的性能直接影响 Kafka 的整体吞吐量。传统的 IO 操作存在多次数据拷贝和上下文切换，性能比较低。Kafka 利用零拷贝技术提升上述过程性能，其中网络数据持久化磁盘主要用 mmap 技术，网络数据传输环节主要使用 Sendfile 技术。</p><p>传统模式下，数据从网络传输到文件需要 4 次数据拷贝、4 次上下文切换和两次系统调用。如下图所示：</p><p><img src="https://blog.mrmanwen.cn/blog/%E6%95%B0%E6%8D%AE%E6%8B%B7%E8%B4%9D%EF%BC%88%E4%BC%A0%E7%BB%9F%E6%96%B9%E5%BC%8F%EF%BC%89.png" alt=""></p><p>为了减少上下文切换以及数据拷贝带来的性能开销，Broker 在对 Producer 传来的网络数据进行持久化时使用了 mmap 技术。通过这种技术手段， Broker 读取到 Socket Buffer 的网络数据，可以直接在内核空间完成落盘，没有必要将 Socket Buffer 的网络数据读取到应用进程缓冲区。</p><p><img src="https://blog.mrmanwen.cn/blog/kafka-%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" alt=""></p><p>Sendfile也是类似的效果，通过 NIO 的transferTo/transferFrom调用操作系统的 Sendfile 实现零拷贝，可以减少上下文切换以及数据拷贝带来的性能开销。</p><h2 id="三、Kafka的应用场景"><a href="#三、Kafka的应用场景" class="headerlink" title="三、Kafka的应用场景"></a>三、Kafka的应用场景</h2><h3 id="（一）异步处理"><a href="#（一）异步处理" class="headerlink" title="（一）异步处理"></a>（一）异步处理</h3><p><img src="https://blog.mrmanwen.cn/blog/kafka-%E5%BC%82%E6%AD%A5%E5%A4%84%E7%90%86.png" alt=""></p><p>场景说明：用户执行下单操作，系统需要完成扣款、更新库存、发货等处理。</p><p>传统方式：用户执行下单后，订单服务接收到消息，需要依次调用支付服务、库存服务、发货服务，所有任务全都执行完成后才将结果返回给用户，那么用户等待的时间会很长，严重影响了用户体验；</p><p>引入Kafka异步处理：订单服务接收用户下单请求后，将订单消息发送给Kafka，支付、库存、发货服务作为消费者，订阅Kafka的主题，读取订单消息后分开执行，降低了系统的耦合度，同时，用户的下单操作是异步的，订单服务发送完消息后，无需等待其他服务的响应即可返回，大幅度降低用户的等待时间。</p><h3 id="（二）流量削峰"><a href="#（二）流量削峰" class="headerlink" title="（二）流量削峰"></a>（二）流量削峰</h3><p><img src="https://blog.mrmanwen.cn/blog/kafka-%E6%B5%81%E9%87%8F%E5%89%8A%E5%B3%B0.png" alt=""></p><p>场景说明：一般用在短时间内处理大量请求，例如：秒杀、服务中的API遭到突发的访问压力等场景，在短时间内流量过大，极容易导致服务过载，应用挂掉。</p><p>引入Kafka实现流量削峰：Kafka 的消息队列可以作为请求的缓冲池，将请求写入 Kafka 队列，消费者可以根据负载情况控制流量的消费速率，避免系统承载超出负荷的流量，达到削峰的目的。</p><h3 id="（三）日志处理与分析"><a href="#（三）日志处理与分析" class="headerlink" title="（三）日志处理与分析"></a>（三）日志处理与分析</h3><p>日志收集是 Kafka 最初的设计目标之一。Kafka可以收集各种服务的日志，如 web 服务器、服务器日志、数据库服务器等，通过Kafka以统一接口服务的方式开放给各种消费者，例如 Flink、Hadoop、Hbase、ElasticSearch 等。这样可以实现分布式系统中海量日志数据的处理与分析。</p><h2 id="四、Kafka的缺点"><a href="#四、Kafka的缺点" class="headerlink" title="四、Kafka的缺点"></a>四、Kafka的缺点</h2><p>虽然 Kafka 是一个高效且强大的分布式消息队列系统，但它也有一些<strong>缺点和限制</strong>。在复杂性方面，维护和管理集群是非常复杂的，需要确保节点、分区等都是实时监控且健康的；在扩容方面，集群中新增的broker只会处理新topic，如果要分担旧分区的压力，需要手动迁移partition，这时会占用大量集群带宽；在消息顺序方面：Kafka 保证了单个分区内的消息顺序，但跨分区的消息顺序是无法保证的。因此，在使用Kafka时，需要重点关注Kafka的缺点问题。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;/&gt;

&lt;h2 id=&quot;一、概述&quot;&gt;&lt;a href=&quot;#一、概述&quot; class=&quot;headerlink&quot; title=&quot;一、概述&quot;&gt;&lt;/a&gt;一、概述&lt;/h2&gt;&lt;p&gt;Kafka &lt;strong&gt;既</summary>
      
    
    
    
    <category term="kafka" scheme="https://mrmancoder.top/categories/kafka/"/>
    
    <category term="消息队列" scheme="https://mrmancoder.top/categories/kafka/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="Kafka" scheme="https://mrmancoder.top/tags/Kafka/"/>
    
    <category term="消息队列" scheme="https://mrmancoder.top/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>Linux安装Docker</title>
    <link href="https://mrmancoder.top/posts/96e9ca9a.html"/>
    <id>https://mrmancoder.top/posts/96e9ca9a.html</id>
    <published>2024-05-21T22:58:06.000Z</published>
    <updated>2025-05-30T18:26:06.992Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-前置说明"><a href="#1-前置说明" class="headerlink" title="1. 前置说明"></a>1. <strong>前置说明</strong></h1><ul><li>本文使用阿里云ECS服务器，系统为Alibaba Cloud Linux 3.2104 LTS 64位，是完全兼容CentOS的。</li><li>CentOS安装Docker官网：<a href="https://docs.docker.com/engine/install/centos/">https://docs.docker.com/engine/install/centos/</a></li></ul><h1 id="2-安装前卸载旧版本"><a href="#2-安装前卸载旧版本" class="headerlink" title="2. 安装前卸载旧版本"></a>2. <strong>安装前卸载旧版本</strong></h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum remove docker \</span><br><span class="line">                  docker-client \</span><br><span class="line">                  docker-client-latest \</span><br><span class="line">                  docker-common \</span><br><span class="line">                  docker-latest \</span><br><span class="line">                  docker-latest-logrotate \</span><br><span class="line">                  docker-logrotate \</span><br><span class="line">                  docker-engine</span><br></pre></td></tr></table></figure><ul><li>直接执行上面的命令，如果出现下面图片的效果，说明系统中没有Docker。</li></ul><p><img src="https://fb48e8e1.telegraph-image-bm7.pages.dev/file/76fb3ee8871ddd3dd62a4.png" alt=""></p><h1 id="3-执行安装"><a href="#3-执行安装" class="headerlink" title="3. 执行安装"></a>3. <strong>执行安装</strong></h1><p><strong>安装yum-utils软件包</strong></p><ul><li>该软件包是一个yum工具集（yum理解为一个包管理器），它提供了一些常用的命令和插件，以便管理和维护yum软件包管理器，其中的 <code>-y</code>表示安装过程中遇到的所有问题全都回答yes。</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install -y yum-utils</span><br></pre></td></tr></table></figure><p><strong>添加Docker仓库</strong></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure><blockquote><ul><li>yum-config-manager：一个管理yum配置的命令行工具；</li><li>—add-repo：添加新的软件仓库，后面的链接为Docker软件仓库；</li></ul></blockquote><p><strong>安装Docker最新版本</strong></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</span><br></pre></td></tr></table></figure><blockquote><p>这个命令安装了 Docker，但是没有启动 Docker。</p><p>它还创建了一个 docker 组，但是默认情况下它不会将任何用户添加到组中。</p></blockquote><p><strong>安装指定版本</strong></p><ul><li>首先执行下面命令列出仓库中可用的版本，显示的第二列就是可用的版本，如图所示。</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum list docker-ce --showduplicates | sort -r</span><br></pre></td></tr></table></figure><p><img src="https://fb48e8e1.telegraph-image-bm7.pages.dev/file/6ed2870a9b8112d6db512.png" alt="img"></p><ul><li>执行安装命令，将自己想要安装的版本替换掉命令中的<VERSION_STRING>即可，例如 <code>docker-ce-3:26.1.3-1.el8</code>。</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io docker-buildx-plugin docker-compose-plugin</span><br></pre></td></tr></table></figure><blockquote><p>现在Docker就已经安装完成了</p></blockquote><h1 id="4-启动Docker"><a href="#4-启动Docker" class="headerlink" title="4. 启动Docker"></a>4. <strong>启动Docker</strong></h1><p><strong>执行启动命令并验证是否启动成功。</strong></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl start docker</span><br><span class="line">sudo docker ps</span><br></pre></td></tr></table></figure><p><strong>如果启动成功，会得到下图的效果。</strong></p><p><img src="https://fb48e8e1.telegraph-image-bm7.pages.dev/file/c9b69496cdf87b2c818f7.png" alt=""></p><h1 id="5-END"><a href="#5-END" class="headerlink" title="5. END"></a>5. <strong>END</strong></h1><p>到这里整个Docker的安装和启动就结束了🍀🍀🍀</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-前置说明&quot;&gt;&lt;a href=&quot;#1-前置说明&quot; class=&quot;headerlink&quot; title=&quot;1. 前置说明&quot;&gt;&lt;/a&gt;1. &lt;strong&gt;前置说明&lt;/strong&gt;&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;本文使用阿里云ECS服务器，系统为Alibaba Clou</summary>
      
    
    
    
    <category term="Docker" scheme="https://mrmancoder.top/categories/Docker/"/>
    
    
    <category term="Linux" scheme="https://mrmancoder.top/tags/Linux/"/>
    
    <category term="Docker" scheme="https://mrmancoder.top/tags/Docker/"/>
    
    <category term="环境搭建" scheme="https://mrmancoder.top/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>布隆过滤器到底是个啥</title>
    <link href="https://mrmancoder.top/posts/6b1c661d.html"/>
    <id>https://mrmancoder.top/posts/6b1c661d.html</id>
    <published>2024-03-12T14:17:23.000Z</published>
    <updated>2025-05-30T18:26:06.992Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-布隆过滤器大致介绍"><a href="#1-布隆过滤器大致介绍" class="headerlink" title="1. 布隆过滤器大致介绍"></a>1. 布隆过滤器大致介绍</h2><ul><li>布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难。</li><li>简单来说，布隆过滤器就是用来<strong>检查一个元素是否在一个集合里的</strong>，接下来就来具体分析下布隆过滤器。。</li></ul><h2 id="2-底层结构"><a href="#2-底层结构" class="headerlink" title="2. 底层结构"></a>2. 底层结构</h2><ul><li>布隆过滤器的底层数据结构是位图，可以理解为只存储二进制数值的数组，每个位置只能存放0或1，<strong>0表示不存在，1表示存在</strong>。</li></ul><p><img src="https://fb48e8e1.telegraph-image-bm7.pages.dev/file/da3dc257ca58012c82f60.png" alt="底层结构"></p><h2 id="3-在缓存穿透中的应用"><a href="#3-在缓存穿透中的应用" class="headerlink" title="3. 在缓存穿透中的应用"></a>3. 在缓存穿透中的应用</h2><h3 id="什么是缓存穿透"><a href="#什么是缓存穿透" class="headerlink" title="什么是缓存穿透"></a>什么是缓存穿透</h3><ul><li>在实际的开发中，难免会遇到数据缓存在redis中，当用户访问数据的时候，都是先请求缓存，那么假如要查询的数据在缓存中和数据库中都不存在，当缓存中查询不出数据的时候，会直接查询数据库，就会造成大量的请求作用到数据库，会对数据库造成很大的压力，容易出现宕机的情况，像恶意攻击，就会出现这种情况，请求查询大量不存在的key，极容易发生宕机，这种情况就叫做缓存穿透。</li></ul><h3 id="缓存穿透的解决办法"><a href="#缓存穿透的解决办法" class="headerlink" title="缓存穿透的解决办法"></a>缓存穿透的解决办法</h3><ol><li>缓存空数据：将从mysql中查询到的空数据缓存到redis中，当用户再来查询的时候，直接查询到redis中的空数据，这种方法比较简单，但是会消耗过大的内存空间；</li><li>第二种方案就是布隆过滤器，当请求查询的是不存在的key值，布隆过滤器会直接返回，不会作用到数据库，这一点是本文重点，接下来会具体讲解。</li></ol><h3 id="布隆过滤器的原理"><a href="#布隆过滤器的原理" class="headerlink" title="布隆过滤器的原理"></a>布隆过滤器的原理</h3><p><strong>添加数据过程</strong></p><ul><li>会先通过k个Hash函数计算hash值；</li><li>然后每个hash映射到不同的数组下标，在下标对应的位置将0改为1，表示元素存在；</li></ul><p><strong>查询数据过程</strong></p><ul><li>同样先通过k个Hash函数计算hash值；</li><li>然后判断每个hash值对应的二进制数字；</li><li>如果所有数字都为1，则说明查询的数据存在，如果有一个为0，则说明数据不存在。</li></ul><p><strong>优点</strong></p><ol><li>存储的是二进制数值，占用空间小；</li><li>插入和删除的速度快，优点类似哈希表的结构，操作k个数值，时间复杂度为O(K)；</li></ol><p><strong>缺点</strong></p><ul><li>可能存在误判：考虑这样一种情况，假如我想要添加两个数据A和B，分别计算他们对应的hash值，如果计算的hash值相同，那他们会同时将某个位置的数值置为1，这时候就不知道此位置的1代表的是什么数据了。<ul><li>接着上面继续分析，如果没有存数据B，此时又想去查询数据B，计算的hash值和A计算的hash值相同，就会得到数据B存在的假现象（此时只有A存在，只不过他们计算的hash相同），形成误判，看图就分析清楚了。</li></ul></li></ul><p><img src="https://fb48e8e1.telegraph-image-bm7.pages.dev/file/0b287b2562ba0eb7c294d.png" alt="误判分析"></p><ul><li>可能存在误删：可以和上面的a一起考虑，假设现在已经添加了数据A和B，但是我想要删除数据A，就会将A计算的hash所对应的索引位置的value置为0，此时B也会被标志删除，因为他们的hash值相同。</li></ul><h3 id="END"><a href="#END" class="headerlink" title="END"></a>END</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-布隆过滤器大致介绍&quot;&gt;&lt;a href=&quot;#1-布隆过滤器大致介绍&quot; class=&quot;headerlink&quot; title=&quot;1. 布隆过滤器大致介绍&quot;&gt;&lt;/a&gt;1. 布隆过滤器大致介绍&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;布隆过滤器（Bloom Filter）是1970年由</summary>
      
    
    
    
    <category term="Redis" scheme="https://mrmancoder.top/categories/Redis/"/>
    
    <category term="布隆过滤器" scheme="https://mrmancoder.top/categories/Redis/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/"/>
    
    
    <category term="Redis" scheme="https://mrmancoder.top/tags/Redis/"/>
    
    <category term="布隆过滤器" scheme="https://mrmancoder.top/tags/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/"/>
    
  </entry>
  
</feed>
